user www-data;
#worker_processes 定义了nginx对外提供web服务时的worder进程数。最优值取决于许多因素，包括（但不限于）CPU核的数量、存储数据的硬盘数量及负载模式。不能确定的时候将其设置为可用的CPU内核数将是一个好的开始（设置为“auto”将尝试自动检测它）
worker_processes auto;

#worker_rlimit_nofile 更改worker进程的最大打开文件数限制。如果没设置的话，这个值为操作系统的限制。设置后你的操作系统和Nginx可以处理比“ulimit -a”更多的文件，所以把这个值设高，这样nginx就不会有“too many open files”问题了。示例:worker_rlimit_nofile 100000;
pid /run/nginx.pid;

#events模块中包含nginx中所有处理连接的设置。
events {
#worker_connections设置可由一个worker进程同时打开的最大连接数。如果设置了上面提到的worker_rlimit_nofile，我们可以将这个值设得很高。记住，最大客户数也由系统的可用socket连接数限制（~ 64K），所以设置不切实际的高没什么好处。
	worker_connections 768;
#multi_accept 告诉nginx收到一个新连接通知后接受尽可能多的连接。
	# multi_accept on;
#use 设置用于复用客户端线程的轮询方法。如果你使用Linux 2.6+，你应该使用epoll。如果你使用*BSD，你应该使用kqueue 示例:use epoll; 
}


#HTTP模块控制着nginx http处理的所有核心特性
http {

	##
	# Basic Settings
	##

#sendfile开启高效文件传输模式，sendfile指令指定nginx是否调用sendfile函数来输出文件，减少用户空间到内核空间的上下文切换
#sendfile()可以在磁盘和TCP socket之间互相拷贝数据(或任意两个文件描述符)。Pre-sendfile是传送数据之前在用户空间申请数据缓冲区。之后用read()将数据从文件拷贝到这个缓冲区，write()将缓冲区数据写入网络。sendfile()是立即将数据从磁盘读到OS缓存。因为这种拷贝是在内核完成的，sendfile()要比组合read()和write()以及打开关闭丢弃缓冲更加有效(更多有关于sendfile)
	sendfile on;
#tcp_nopush 告诉nginx在一个数据包里发送所有头文件，而不一个接一个的发送
	tcp_nopush on;
#tcp_nodelay 告诉nginx不要缓存数据，而是一段一段的发送–当需要及时发送数据时，就应该给应用设置这个属性，这样发送一小块数据信息时就不能立即得到返回值
	tcp_nodelay on;
#keepalive_timeout 给客户端分配keep-alive链接超时时间。服务器将在这个超时时间过后关闭链接。我们将它设置低些可以让ngnix持续工作的时间更长
	keepalive_timeout 65;
	types_hash_max_size 2048;

#client_header_timeout 和client_body_timeout 设置请求头和请求体(各自)的超时时间。我们也可以把这个设置低些,示例:client_header_timeout 10;client_body_timeout 10;

#reset_timeout_connection告诉nginx关闭不响应的客户端连接。这将会释放那个客户端所占有的内存空间。示例:reset_timedout_connection on;

#send_timeout 指定客户端的响应超时时间。这个设置不会用于整个转发器，而是在两次客户端读取操作之间。如果在这段时间内，客户端没有读取任何数据，nginx就会关闭连接, 示例：send_timeout 10;

#limit_conn为给定的key设置最大连接数。这里key是addr，我们设置的值是100，也就是说我们允许每一个IP地址最多同时打开有100个连接。limit_conn_zone $binary_remote_addr zone=addr:5m;

#limit_conn_zone设置用于保存各种key（比如当前连接数）的共享内存的参数。5m就是5兆字节，这个值应该被设置的足够大以存储（32K*5）32byte状态或者（16K*5）64byte状态 limit_conn addr 100;


#server_tokens 并不会让nginx执行的速度更快，但它可以关闭在错误页面中的nginx版本数字，这样对于安全性是有好处的
	# server_tokens off;

	# server_names_hash_bucket_size 64;
	# server_name_in_redirect off;

#include 只是一个在当前文件中包含另一个文件内容的指令。这里我们使用它来加载稍后会用到的一系列的MIME类型。
	include /etc/nginx/mime.types;
#default_type 设置文件使用的默认的MIME-type。
	default_type application/octet-stream;
#charset 设置我们的头文件中的默认的字符集 charset UTF-8;

	##
	# SSL Settings
	##

	ssl_protocols TLSv1 TLSv1.1 TLSv1.2; # Dropping SSLv3, ref: POODLE
	ssl_prefer_server_ciphers on;

	##
	# Logging Settings
	##
#access_log设置nginx是否将存储访问日志。关闭这个选项可以让读取磁盘IO操作更快
	access_log /var/log/nginx/access.log;
#error_log 告诉nginx只能记录严重的错误
	error_log /var/log/nginx/error.log;

	##
	# Gzip Settings
	##
#gzip是告诉nginx采用gzip压缩的形式发送数据。这将会减少我们发送的数据量。
# 默认情况下，Nginx的gzip压缩是关闭的， gzip压缩功能就是可以让你节省不
# 少带宽，但是会增加服务器CPU的开销哦，Nginx默认只对text/html进行压缩 ，
# 如果要对html之外的内容进行压缩传输，我们需要手动来设置。
	gzip on;
#gzip_disable为指定的客户端禁用gzip功能。我们设置成IE6或者更低版本以使我们的方案能够广泛兼容。
	gzip_disable "msie6";

#gzip_min_length设置对数据启用压缩的最少字节数。如果一个请求小于1000字节，我们最好不要压缩它，因为压缩这些小的数据会降低处理此请求的所有进程的速度。gzip_min_length 1000;

	# gzip_vary on;
#gzip_proxied允许或者禁止压缩基于请求和响应的响应流。我们设置为any，意味着将会压缩所有的请求。
	# gzip_proxied any;
#gzip_comp_level设置数据的压缩等级。这个等级可以是1-9之间的任意数值，9是最慢但是压缩比最大的。我们设置为4，这是一个比较折中的设置。
	# gzip_comp_level 6;
	# gzip_buffers 16 8k;
	# gzip_http_version 1.1;

#gzip_type设置需要压缩的数据格式。上面例子中已经有一些了，你也可以再添加更多的格式。
	# gzip_types text/plain text/css application/json application/javascript text/xml application/xml application/xml+rss text/javascript;

#open_file_cache打开缓存的同时也指定了缓存最大数目，以及缓存的时间。我们可以设置一个相对高的最大时间，这样我们可以在它们不活动超过20秒后清除掉。
# 这个将为打开文件指定缓存，默认是没有启用的，max 指定缓存数量，建议和打开文件数一致，inactive 是指经过多长时间文件没被请求后删除缓存。
#open_file_cache max=100000 inactive=20s;


#这个是指多长时间检查一次缓存的有效信息
#open_file_cache_valid 在open_file_cache中指定检测正确信息的间隔时间。open_file_cache_valid 30s;

# open_file_cache 指令中的inactive 参数时间内文件的最少使用次数，
# 如果超过这个数字，文件描述符一直是在缓存中打开的，如上例，如果有一个
# 文件在inactive 时间内一次没被使用，它将被移除。
#open_file_cache_min_uses 定义了open_file_cache中指令参数不活动时间期间里最小的文件数。open_file_cache_min_uses 1;

#open_file_cache_errors指定了当搜索一个文件时是否缓存错误信息，也包括再次给配置中添加文件。我们也包括了服务器模块，这些是在不同文件中定义的。如果你的服务器模块不在这些位置，你就得修改这一行来指定正确的位置。open_file_cache_errors on;

#nginx对哪些进行缓存？
#1. 缓存没有 Set-Cookie 的GET和HEAD的响应。
#2. 通过定义独特的原始URL，如proxy_cache_key。
#3. 通过定义缓存时间，如X-Accel-Expires、Cache-Control、Expires。
#proxy_cache_path 用来设置缓存的路径和配置
#用于缓存的本地磁盘目录是 /path/to/cache/
#levels 在 /path/to/cache/ 设置了一个两级层次结构的目录。将大量的文件放置在单个目录中会导致文件访问缓慢，所以针对大多数部署，我们推荐使用两级目录层次结构。如果 levels 参数没有配置，则 Nginx 会将所有的文件放到同一个目录中。
#max_size 设置了缓存的上限（在上面的例子中是 10G）。这是一个可选项；如果不指定具体值，那就是允许缓存不断增长，占用所有可用的磁盘空间。当缓存达到这个上线，处理器便调用 cache manager 来移除最近最少被使用的文件，这样把缓存的空间降低至这个限制之下。
#inactive 指定了项目在不被访问的情况下能够在内存中保持的时间。在上面的例子中，如果一个文件在 60 分钟之内没有被请求，则缓存管理将会自动将其在内存中删除，不管该文件是否过期。该参数默认值为 10 分钟（10m）。注意，非活动内容有别于过期内容。 Nginx 不会自动删除由缓存控制头部指定的过期内容（本例中 Cache-Control:max-age=120）。过期内容只有在 inactive 指定时间内没有被访问的情况下才会被删除。如果过期内容被访问了，那么 Nginx 就会将其从原服务器上刷新，并更新对应的inactive计时器
#Nginx 最初会将注定写入缓存的文件先放入一个临时存储区域，use_temp_path=off命令指示 Nginx 将在缓存这些文件时将它们写入同一个目录下。我们强烈建议你将参数设置为off来避免在文件系统中不必要的数据拷贝。use_temp_path在 Nginx 1.7版本和 Nginx Plus R6中有所介绍。
proxy_cache_path /path/to/cache levels=1:2 keys_zone=my_cache:10m max_size=10g inactive=60m use_temp_path=off;
#proxy_cache 用来启用缓存。
#最终，proxy_cache 命令启动缓存那些URL与location部分匹配的内容（本例中，为/）。你同样可以将proxy_cache命令添加到server部分，这将会将缓存应用到所有的那些location中未指定自己的proxy_cache命令的服务中
#location / {
#       proxy_cache my_cache;
#       proxy_pass http://my_upstream;
#   }

	##
	# Virtual Host Configs
	##

	include /etc/nginx/conf.d/*.conf;
	include /etc/nginx/sites-enabled/*;


	#日志格式，默认为combined	
	log_format  proxy  '$http_x_forwarded_for - $remote_user  [$time_local]  '
                             ' "$request"  $status $body_bytes_sent '
                             ' "$http_referer"  "$http_user_agent" ';
	#日志运行包含的变量
	#$remote_addr, $http_x_forwarded_for 记录客户端IP地址
	#$remote_user 记录客户端用户名称
	#$request 记录请求的URL和HTTP协议
	#$status 记录请求状态
	#$body_bytes_sent 发送给客户端的字节数，不包括响应头的大小； 该变量与Apache模块mod_log_config里的“%B”参数兼容。
	#$bytes_sent 发送给客户端的总字节数。
	#$connection 连接的序列号。
	#$connection_requests 当前通过一个连接获得的请求数量。
	#$msec 日志写入时间。单位为秒，精度是毫秒。
	#$pipe 如果请求是通过HTTP流水线(pipelined)发送，pipe值为“p”，否则为“.”。
	#$http_referer 记录从哪个页面链接访问过来的
	#$http_user_agent 记录客户端浏览器相关信息
	#$request_length 请求的长度（包括请求行，请求头和请求正文）。
	#$request_time 请求处理时间，单位为秒，精度毫秒； 从读入客户端的第一个字节开始，直到把最后一个字符发送给客户端后进行日志写入为止。
	#$time_iso8601 ISO8601标准格式下的本地时间。
	#$time_local 通用日志格式下的本地时间

	#ngx_http_upstream_module可以用来实现web服务器（tomcat）的负载均衡
	#默认采用轮询策略
	upstream my_service {
	      server 192.168.3.8:9000;
	      server 192.168.3.8:9001;
	}
	#权重：指定轮询几率，weight和访问比率成正比，用于后端服务器性能不均的情况。如下所示，9001的访问比率要比9000的访问比率高一倍
	upstream my_service_weight {
	      server 192.168.3.8:9000 weight=1;
	      server 192.168.3.8:9001 weight=2;
	}
	#ip_hash:每个请求按访问ip的hash结果分配，这样每个访客固定访问一个后端服务器，可以解决session的问题。
	upstream my_service_ip_hash {
	      ip_hash;
	      server 192.168.3.8:9000;
	      server 192.168.3.8:9001;
	}
	#least_conn最少连接：least_conn算法很简单，首选遍历后端集群，比较每个后端的conns/weight，选取该值最小的后端。
	#如果有多个后端的conns/weight值同为最小的，那么对它们采用加权轮询算法。
	upstream my_service_least_conn {
	      least_conn;
	      server 192.168.3.8:9000;
	      server 192.168.3.8:9001;
	}
	#url_hash（第三方）:按访问url的hash结果来分配请求，使每个url定向到同一个后端服务器，后端服务器为缓存时比较有效。
	#注意：在upstream中加入hash语句，server语句中不能写入weight等其他的参数.
	#Nginx 本身是不支持 url_hash 的，如果需要使用这种调度算法，必须安装 Nginx 的 hash 软件包。
	upstream my_service_url_hash {
	      hash $request_uri;
	      server 192.168.3.8:9000;
	      server 192.168.3.8:9001;
	}
	#fair（第三方）:    按后端服务器的响应时间来分配请求，响应时间短的优先分配。与weight分配策略类似
	#Nginx本身是不支持fair的，如果需要使用这种调度算法，必须下载Nginx的upstream_fair模块。
	#upstream my_service_fair {
	#      fair;
	#      server 192.168.3.8:9000;
	#      server 192.168.3.8:9001;
	#}
	
	#upstream还可以为每个设备设置状态值，这些状态值的含义分别如下：
	#down 表示单前的server暂时不参与负载.
	#weight 默认为1.weight越大，负载的权重就越大。
	#max_fails ：允许请求失败的次数默认为1.当超过最大次数时，返回proxy_next_upstream 模块定义的错误.
	#fail_timeout : max_fails次失败后，暂停的时间。
	#backup： 其它所有的非backup机器down或者忙的时候，请求backup机器。所以这台机器压力会最轻。不能和ip_hash混用
	upstream my_service2 {
	      ip_hash;
	      server 192.168.3.8:9000 weight=2;
	      server 192.168.3.8:9001;	      
	      server 192.168.3.8:9003 down;
	}

#server可以重复添加多个,可以通过ifconfig命令向同一个网卡增加多个IP
	server {
		#监听对IP和端口,可以不带IP，表示监听服务器上所有IP对80端口
		 listen 192.168.3.8:80;
		#主机名称
		 server_name 192.168.3.8;
		 charset utf-8;
		#访问日志存放路径，其中默认对combined日志格式可以忽略;
		#access_log path [format [buffer=size | off]]
		#如果不想记录日志，可以关闭日志access_log off;
		#路径也可以包含变量，入$server_name
		 access_log /var/log/nginx/server1.access.log proxy;
		error_log  /var/log/nginx/server1.error.log;

		location /loadbalance {
			    ## 将proxy_pass配置为upstream中定义的名称
			    proxy_pass http://my_service;
		}
		location /loadbalance_weight {
			    ## 将proxy_pass配置为upstream中定义的名称
			    proxy_pass http://my_service_weight;
		}
		location /loadbalance_ip_hash {
			    ## 将proxy_pass配置为upstream中定义的名称
			    proxy_pass http://my_service_ip_hash;
		}
		location /loadbalance_ip_hash2 {
			    ## 将proxy_pass配置为upstream中定义的名称
			    proxy_pass http://my_service2;
		}
		location /loadbalance_least_conn {
			    ## 将proxy_pass配置为upstream中定义的名称
			    proxy_pass http://my_service_least_conn;
		}
		location /loadbalance_url_hash {
			    ## 将proxy_pass配置为upstream中定义的名称
			    proxy_pass http://my_service_url_hash;
		}
		
		#= 开头表示精确匹配
		location = /api {
		#proxy_cache 命令启动缓存那些URL与location部分匹配的内容（本例中，为/api）。你同样可以将proxy_cache命令添加到server部分，这将会将缓存应用到所有的那些location中未指定自己的proxy_cache命令的服务中
			#proxy_cache my_cache;
			proxy_pass http://my_upstream;
		#陈旧总比没有强。Nginx 内容缓存的一个非常强大的特性是：当无法从原始服务器获取最新的内容时， Nginx 可以分发缓存中的陈旧（stale，编者注：即过期内容）内容。这种情况一般发生在关联缓存内容的原始服务器宕机或者繁忙时。比起对客户端传达错误信息， Nginx 可发送在其内存中的陈旧的文件。 Nginx 的这种代理方式，为服务器提供额外级别的容错能力，并确保了在服务器故障或流量峰值的情况下的正常运行。为了开启该功能，只需要添加 proxy_cache_use_stale 命令即可：
		#proxy_cache_use_stale error timeout http_500 http_502 http_503 http_504;
		#按照上面例子中的配置，当 Nginx 收到服务器返回的error，timeout或者其他指定的5xx错误，并且在其缓存中有请求文件的陈旧版本，则会将这些陈旧版本的文件而不是错误信息发送给客户端。
		#proxy_cache_revalidate on;
		#proxy_cache_revalidate 指示 Nginx 在刷新来自服务器的内容时使用 GET 请求。如果客户端的请求项已经被缓存过了，但是在缓存控制头部中定义为过期，那么 Nginx 就会在 GET 请求中包含 If-Modified-Since 字段，发送至服务器端。这项配置可以节约带宽，因为对于 Nginx 已经缓存过的文件，服务器只会在该文件请求头中 Last-Modified 记录的时间内被修改时才将全部文件一起发送。
		proxy_cache_min_uses 3;
		#proxy_cache_min_uses 该指令设置同一链接请求达到几次即被缓存，默认值为 1 。当缓存不断被填满时，这项设置便十分有用，因为这确保了只有那些被经常访问的内容会被缓存。
		proxy_cache_lock on;
		#当 proxy_cache_lock 被启用时，当多个客户端请求一个缓存中不存在的文件（或称之为一个 MISS），只有这些请求中的第一个被允许发送至服务器。其他请求在第一个请求得到满意结果之后在缓存中得到文件。如果不启用 proxy_cache_lock，则所有在缓存中找不到文件的请求都会直接与服务器通信。
		}

		#反向代理
		## 1. 用户访问 http://ip:port，则反向代理到 https://github.com
		location /github {
		#proxy_pass 后面跟着一个 URL，用来将请求反向代理到 URL 参数指定的服务器上
		    proxy_pass  https://github.com;
		    #proxy_redirect     off;
		#默认情况下，反向代理不会转发原始请求中的 Host 头部，如果需要转发，就需要加上这句
		    proxy_set_header   Host             $host;
		    proxy_set_header   X-Real-IP        $remote_addr;
		    proxy_set_header   X-Forwarded-For  $proxy_add_x_forwarded_for;
		}
		#^~ 开头表示 uri 以某个常规字符串开头，理解为匹配 url 路径即可。nginx 不对 url 做编码，因此请求为/static/20%/aa，可以被规则^~ /static/ /aa匹配到（注意是空格），注意，/static/index.html请求的是/home/edgar/static/static/index.html
		location ^~ /static/ {
			root /home/edgar/static/;
		}
		#~ 开头表示区分大小写的正则匹配
		location ~ \.(gif|jpg|png|js|css)$ {
			 root /home/edgar/server1/res;
		}
		#~* 开头表示不区分大小写的正则匹配
		location ~* \.png$ {
			 root /home/edgar/server1/static/res;
		}
		#/ 通用匹配，任何请求都会匹配到
		 location / {
		#默认首页文件，顺序从左到右
		#实际使用中，index应该放在HTTP区块里面继承
		  index index.html index.htm;
		#网页文件存放路径
		#实际使用中，root应该放在location外面
		 root /home/edgar/server1;
		}
	}

}


#mail {
#	# See sample authentication script at:
#	# http://wiki.nginx.org/ImapAuthenticateWithApachePhpScript
# 
#	# auth_http localhost/auth.php;
#	# pop3_capabilities "TOP" "USER";
#	# imap_capabilities "IMAP4rev1" "UIDPLUS";
# 
#	server {
#		listen     localhost:110;
#		protocol   pop3;
#		proxy      on;
#	}
# 
#	server {
#		listen     localhost:143;
#		protocol   imap;
#		proxy      on;
#	}
#}
